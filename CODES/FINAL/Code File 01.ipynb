{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff088f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1660 Ti\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f59d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_ESRGAN_INPUTS = \"Real-ESRGAN/inputs/\"\n",
    "REAL_ESRGAN_OUTPUTS = \"Real-ESRGAN/results/\"\n",
    "\n",
    "Parent_Data_Path = \"Data 01/\"\n",
    "\n",
    "PAGES_PATH = \"Data 01/Pages/\"\n",
    "PAGES_ENHANCED_PATH = \"Data 01/Pages - Enhanced/\"\n",
    "\n",
    "WORDS_PATH = \"Data 01/Words/\"\n",
    "WORDS_ENHANCED_PATH = \"Data 01/Words - Enhanced/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04ee64d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\ahbaz/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2022-3-3 torch 1.8.2+cu102 CUDA:0 (NVIDIA GeForce GTX 1660 Ti, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7053277 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5-word/runs/train/exp28/weights/last.pt', force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4cc0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_RESRNGAN_inputs():\n",
    "    for file in os.scandir(REAL_ESRGAN_INPUTS):\n",
    "        os.remove(file.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27c3d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_RESRNGAN_outputs():\n",
    "    for file in os.scandir(REAL_ESRGAN_OUTPUTS):\n",
    "        os.remove(file.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b383d6e8",
   "metadata": {},
   "source": [
    "# Page Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead75987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Page_Clipper(img, Cutter_Square_Size = 100):\n",
    "    Cutter_Page = []\n",
    "    for rect in range(1, int(img.shape[0]/Cutter_Square_Size) + 2):\n",
    "        r = img[(rect - 1) * Cutter_Square_Size: rect * Cutter_Square_Size,:]\n",
    "        temp = []\n",
    "        for sq in range(1, int(r.shape[1]/Cutter_Square_Size) + 2):\n",
    "            s = r[:, (sq - 1) * Cutter_Square_Size: sq * Cutter_Square_Size]\n",
    "            temp.append(s)\n",
    "        Cutter_Page.append(temp)\n",
    "    return Cutter_Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eb618cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_RESRNGAN_inputs()\n",
    "delete_RESRNGAN_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6acf8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Page_Enhancement(page, Cutter_Square_Size = 100, factor = 0.5):\n",
    "    Cutter_Page = Page_Clipper(page, Cutter_Square_Size)\n",
    "    \n",
    "    temp_final = []\n",
    "    for r1 in Cutter_Page:\n",
    "        delete_RESRNGAN_inputs()\n",
    "        delete_RESRNGAN_outputs()\n",
    "        i = 0\n",
    "        for r2 in r1:\n",
    "            cv2.imwrite(REAL_ESRGAN_INPUTS + \"img \" + chr(65 + i) + '.jpg', r2)\n",
    "            i += 1\n",
    "\n",
    "        time.sleep(1)\n",
    "        torch.cuda.empty_cache()\n",
    "        os.chdir('Real-ESRGAN/')\n",
    "        !python inference_realesrgan.py --model_path experiments/pretrained_models/RealESRGAN_x4plus.pth --input inputs\n",
    "        time.sleep(1)\n",
    "        os.chdir('..')\n",
    "\n",
    "        temp = []\n",
    "        for r in os.scandir(REAL_ESRGAN_OUTPUTS):\n",
    "            if r.is_file():\n",
    "                img = Image.open(r.path)\n",
    "                transform = transforms.Resize(size=(int(img.size[1] * factor), int(img.size[0] * factor)))\n",
    "                img = np.asarray(transform(img))\n",
    "                temp.append(img)\n",
    "        rect = np.concatenate(temp, axis = 1)\n",
    "        temp_final.append(rect)\n",
    "        delete_RESRNGAN_inputs()\n",
    "        delete_RESRNGAN_outputs()\n",
    "    temp_final = np.concatenate(temp_final, axis = 0)\n",
    "    return temp_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25fe0012",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 0 img A\n",
      "Testing 1 img B\n",
      "Testing 2 img C\n",
      "Testing 3 img D\n",
      "Testing 4 img E\n",
      "Testing 5 img F\n",
      "Testing 6 img G\n",
      "Testing 7 img H\n",
      "Testing 8 img I\n",
      "Testing 9 img J\n",
      "Testing 0 img A\n",
      "Testing 1 img B\n",
      "Testing 2 img C\n",
      "Testing 3 img D\n",
      "Testing 4 img E\n",
      "Testing 5 img F\n",
      "Testing 6 img G\n",
      "Testing 7 img H\n",
      "Testing 8 img I\n",
      "Testing 9 img J\n",
      "Testing 0 img A\n",
      "Testing 1 img B\n",
      "Testing 2 img C\n",
      "Testing 3 img D\n",
      "Testing 4 img E\n",
      "Testing 5 img F\n",
      "Testing 6 img G\n",
      "Testing 7 img H\n",
      "Testing 8 img I\n",
      "Testing 9 img J\n",
      "Testing 0 img A\n",
      "Testing 1 img B\n",
      "Testing 2 img C\n",
      "Testing 3 img D\n",
      "Testing 4 img E\n",
      "Testing 5 img F\n",
      "Testing 6 img G\n",
      "Testing 7 img H\n",
      "Testing 8 img I\n",
      "Testing 9 img J\n",
      "Testing 0 img A\n",
      "Testing 1 img B\n",
      "Testing 2 img C\n",
      "Testing 3 img D\n",
      "Testing 4 img E\n",
      "Testing 5 img F\n",
      "Testing 6 img G\n",
      "Testing 7 img H\n",
      "Testing 8 img I\n",
      "Testing 9 img J\n",
      "Testing 0 img A\n",
      "Testing 1 img B\n",
      "Testing 2 img C\n",
      "Testing 3 img D\n",
      "Testing 4 img E\n",
      "Testing 5 img F\n",
      "Testing 6 img G\n",
      "Testing 7 img H\n",
      "Testing 8 img I\n",
      "Testing 9 img J\n",
      "Testing 0 img A\n",
      "Testing 1 img B\n",
      "Testing 2 img C\n",
      "Testing 3 img D\n",
      "Testing 4 img E\n",
      "Testing 5 img F\n",
      "Testing 6 img G\n",
      "Testing 7 img H\n",
      "Testing 8 img I\n",
      "Testing 9 img J\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for page_path in os.scandir(PAGES_PATH):\n",
    "    if page_path.is_file():\n",
    "        page = Page_Enhancement(cv2.imread(page_path.path))\n",
    "        cv2.imwrite(PAGES_ENHANCED_PATH + 'Page ' + chr(65 + i) + '.jpg', page)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff74df",
   "metadata": {},
   "source": [
    "# Word Cuttouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eea3fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Word_Extraction(page, min_conf = 0.75):\n",
    "    page_result = model(page)\n",
    "    \n",
    "    coordinates = []\n",
    "    words = []\n",
    "    for e in page_result.crop():\n",
    "        if e['conf'].item() >= min_conf:\n",
    "            x1 = e['box'][0].item()\n",
    "            y1 = e['box'][1].item()\n",
    "            x2 = e['box'][2].item()\n",
    "            y2 = e['box'][3].item()\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            xm = x1 + (w/2)\n",
    "            ym = y2 + (h/2)\n",
    "            x1_1 = x1 + w\n",
    "            y1_1 = y1\n",
    "            coordinates.append([x1, y1, x2, y2, h, w, x1_1, y1_1, xm, ym])\n",
    "            words.append(e['im'])\n",
    "\n",
    "    df = pd.DataFrame(coordinates, columns=['x1', 'y1', 'x2', 'y2', 'h', 'w', 'x1_1', 'y1_1', 'xm', 'ym'])\n",
    "\n",
    "    sorted_lines_index = []\n",
    "    x_origin, y_origin = int(page.shape[1] / 2), 0\n",
    "\n",
    "    while True:\n",
    "        df['R'] = (abs(x_origin - df['x1']) + abs(y_origin - df['y1'])).to_list()\n",
    "        index_ref = df.sort_values(by = ['R']).index[0]\n",
    "        y_ref = df.loc[index_ref].y1\n",
    "        h_ref = df.loc[index_ref].h\n",
    "        print(index_ref)\n",
    "        df['dis'] = (df.y1 - y_ref - (h_ref / 2)).to_list()\n",
    "        # (df['dis'] < 0).sum()\n",
    "        sorted_line_index = df[df['dis'] < 0].sort_values(by = ['x1']).index.to_list()\n",
    "        sorted_lines_index.append(sorted_line_index)\n",
    "        df.drop(sorted_line_index, inplace=True)\n",
    "        del df['R']\n",
    "        del df['dis']\n",
    "\n",
    "        if df.shape[0] <= 0:\n",
    "            break\n",
    "\n",
    "    return sorted_lines_index, coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9341bbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved 1 image to \u001b[1mruns\\detect\\exp3\u001b[0m\n",
      "Saved results to runs\\detect\\exp3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "81\n",
      "43\n",
      "53\n",
      "13\n",
      "127\n",
      "68\n",
      "7\n",
      "86\n",
      "24\n",
      "80\n",
      "124\n",
      "63\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "for page_enhanced_path in os.scandir(PAGES_ENHANCED_PATH):\n",
    "    if page_enhanced_path.is_file():\n",
    "        page_name = page_enhanced_path.path.split('/')[-1].split('.')[0]\n",
    "        page = cv2.imread(page_enhanced_path.path)\n",
    "        sorted_lines_index, coordinates = Word_Extraction(page)\n",
    "        \n",
    "        if not os.path.isdir(WORDS_PATH + page_name):\n",
    "            os.mkdir(WORDS_PATH + page_name, mode=511)\n",
    "            \n",
    "        i = 1\n",
    "        for line in sorted_lines_index:\n",
    "            for word in line:\n",
    "                croped_word = page[int(coordinates[word][1]) : int(coordinates[word][3]), int(coordinates[word][0]) : int(coordinates[word][2])]\n",
    "\n",
    "                cv2.imwrite(WORDS_PATH + page_name + '/' + 'Word ' + str(i) + '.jpg', croped_word)\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a5f8a",
   "metadata": {},
   "source": [
    "# Word Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e9f01d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Word_Enhancement(words, factor = 0.5):\n",
    "    delete_RESRNGAN_inputs()\n",
    "    delete_RESRNGAN_outputs()\n",
    "\n",
    "    i = 0\n",
    "    for word in words:\n",
    "        cv2.imwrite(REAL_ESRGAN_INPUTS + \"img \" + str(i) + '.jpg', word)\n",
    "        i += 1\n",
    "\n",
    "    time.sleep(1)\n",
    "    torch.cuda.empty_cache()\n",
    "    os.chdir('Real-ESRGAN/')\n",
    "    !python inference_realesrgan.py --model_path experiments/pretrained_models/RealESRGAN_x4plus.pth --input inputs\n",
    "    time.sleep(1)\n",
    "    os.chdir('..')\n",
    "\n",
    "    words_final = []\n",
    "    for r in os.scandir(REAL_ESRGAN_OUTPUTS):\n",
    "        if r.is_file():\n",
    "            img = Image.open(r.path)\n",
    "            transform = transforms.Resize(size=(int(img.size[1] * factor), int(img.size[0] * factor)))\n",
    "            img = np.asarray(transform(img))\n",
    "            words_final.append(img)\n",
    "            \n",
    "    delete_RESRNGAN_inputs()\n",
    "    delete_RESRNGAN_outputs()\n",
    "\n",
    "    return words_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5261b114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 0 img 0\n",
      "Testing 1 img 1\n",
      "Testing 2 img 10\n",
      "Testing 3 img 100\n",
      "Testing 4 img 101\n",
      "Testing 5 img 102\n",
      "Testing 6 img 103\n",
      "Testing 7 img 104\n",
      "Testing 8 img 105\n",
      "Testing 9 img 106\n",
      "Testing 10 img 107\n",
      "Testing 11 img 108\n",
      "Testing 12 img 109\n",
      "Testing 13 img 11\n",
      "Testing 14 img 110\n",
      "Testing 15 img 111\n",
      "Testing 16 img 112\n",
      "Testing 17 img 113\n",
      "Testing 18 img 114\n",
      "Testing 19 img 115\n",
      "Testing 20 img 116\n",
      "Testing 21 img 117\n",
      "Testing 22 img 118\n",
      "Testing 23 img 119\n",
      "Testing 24 img 12\n",
      "Testing 25 img 120\n",
      "Testing 26 img 121\n",
      "Testing 27 img 122\n",
      "Testing 28 img 123\n",
      "Testing 29 img 124\n",
      "Testing 30 img 125\n",
      "Testing 31 img 126\n",
      "Testing 32 img 127\n",
      "Testing 33 img 128\n",
      "Testing 34 img 129\n",
      "Testing 35 img 13\n",
      "Testing 36 img 14\n",
      "Testing 37 img 15\n",
      "Testing 38 img 16\n",
      "Testing 39 img 17\n",
      "Testing 40 img 18\n",
      "Testing 41 img 19\n",
      "Testing 42 img 2\n",
      "Testing 43 img 20\n",
      "Testing 44 img 21\n",
      "Testing 45 img 22\n",
      "Testing 46 img 23\n",
      "Testing 47 img 24\n",
      "Testing 48 img 25\n",
      "Testing 49 img 26\n",
      "Testing 50 img 27\n",
      "Testing 51 img 28\n",
      "Testing 52 img 29\n",
      "Testing 53 img 3\n",
      "Testing 54 img 30\n",
      "Testing 55 img 31\n",
      "Testing 56 img 32\n",
      "Testing 57 img 33\n",
      "Testing 58 img 34\n",
      "Testing 59 img 35\n",
      "Testing 60 img 36\n",
      "Testing 61 img 37\n",
      "Testing 62 img 38\n",
      "Testing 63 img 39\n",
      "Testing 64 img 4\n",
      "Testing 65 img 40\n",
      "Testing 66 img 41\n",
      "Testing 67 img 42\n",
      "Testing 68 img 43\n",
      "Testing 69 img 44\n",
      "Testing 70 img 45\n",
      "Testing 71 img 46\n",
      "Testing 72 img 47\n",
      "Testing 73 img 48\n",
      "Testing 74 img 49\n",
      "Testing 75 img 5\n",
      "Testing 76 img 50\n",
      "Testing 77 img 51\n",
      "Testing 78 img 52\n",
      "Testing 79 img 53\n",
      "Testing 80 img 54\n",
      "Testing 81 img 55\n",
      "Testing 82 img 56\n",
      "Testing 83 img 57\n",
      "Testing 84 img 58\n",
      "Testing 85 img 59\n",
      "Testing 86 img 6\n",
      "Testing 87 img 60\n",
      "Testing 88 img 61\n",
      "Testing 89 img 62\n",
      "Testing 90 img 63\n",
      "Testing 91 img 64\n",
      "Testing 92 img 65\n",
      "Testing 93 img 66\n",
      "Testing 94 img 67\n",
      "Testing 95 img 68\n",
      "Testing 96 img 69\n",
      "Testing 97 img 7\n",
      "Testing 98 img 70\n",
      "Testing 99 img 71\n",
      "Testing 100 img 72\n",
      "Testing 101 img 73\n",
      "Testing 102 img 74\n",
      "Testing 103 img 75\n",
      "Testing 104 img 76\n",
      "Testing 105 img 77\n",
      "Testing 106 img 78\n",
      "Testing 107 img 79\n",
      "Testing 108 img 8\n",
      "Testing 109 img 80\n",
      "Testing 110 img 81\n",
      "Testing 111 img 82\n",
      "Testing 112 img 83\n",
      "Testing 113 img 84\n",
      "Testing 114 img 85\n",
      "Testing 115 img 86\n",
      "Testing 116 img 87\n",
      "Testing 117 img 88\n",
      "Testing 118 img 89\n",
      "Testing 119 img 9\n",
      "Testing 120 img 90\n",
      "Testing 121 img 91\n",
      "Testing 122 img 92\n",
      "Testing 123 img 93\n",
      "Testing 124 img 94\n",
      "Testing 125 img 95\n",
      "Testing 126 img 96\n",
      "Testing 127 img 97\n",
      "Testing 128 img 98\n",
      "Testing 129 img 99\n"
     ]
    }
   ],
   "source": [
    "for page_name_path in os.scandir(WORDS_PATH):\n",
    "    words = []\n",
    "    for word_path in os.scandir(page_name_path.path):\n",
    "        word = cv2.imread(word_path.path)\n",
    "        words.append(word)\n",
    "    words = Word_Enhancement(words)\n",
    "    \n",
    "    page_name = page_name_path.path.split('/')[-1]\n",
    "    if not os.path.isdir(WORDS_ENHANCED_PATH + page_name):\n",
    "        os.mkdir(WORDS_ENHANCED_PATH + page_name, mode=511)\n",
    "\n",
    "    i = 1\n",
    "    for word in words:\n",
    "        cv2.imwrite(WORDS_ENHANCED_PATH + page_name + '/' + 'Word ' + str(i) + '.jpg', word)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35dcfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "A_1",
   "language": "python",
   "name": "a_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
